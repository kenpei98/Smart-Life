{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Model Structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#Define a new class named SimpleNet, this class have extends the nn.Module class\n",
    "#In the constructor of the class, it specify all the layers in our network. The network is structured as convolution,\n",
    "#relu, convolution, relu, pool, convolution, relu, convolution, relu, linear\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        #Understand Convolution layer which Conv2d: Given our input as RGB images which contains 3 channels(RGB means Red-Green-Blue), thus we specify \n",
    "        #in_channels = 3. Since we want apply 12 feature detectors to the images, so we set out_channels = 12. We use \n",
    "        #standard 3*3 kernel size, thus kernel_size = 3. Stride = 1 means the convolution would movel 1 pixel at a time. \n",
    "        #padding = 1, this will ensures our images are padded with zeros to keep the input and output size the same.\n",
    "        #** The out_channels in one layer will serves as the in_channels in the next layer.\n",
    "        self.relu1 = nn.ReLU()\n",
    "        #Understand ReLU layer which ReLU: This is the standard ReLU activation function, it will thresholds all incoming featuers to\n",
    "        #be 0 or greater. In other words, when you apply relu to the incoming features, any number less than 0 will change to\n",
    "        #zero, while others are kept the same.\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        #Understand MaxPool2d layer which MaxPool2d: This layer will reduce the dimension of the images, in here, reduce the image\n",
    "        #by setting the kernel_size=2, reducing our image width and height by a factor of 2.\n",
    "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3= nn.ReLU()\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        #This layer has output channels(out_channels) is 24. Due to 2*2 max pooling, so at this point our image has become\n",
    "        #16*16(original, we have 32*32 pixels for images, now 32/2=16).\n",
    "        self.fc = nn.linear(in_features=16*16*24, out_features=num_classes)\n",
    "        #Understand linear layer which linear: This layer always be the last layer of our network. We have to flatten the entire feature\n",
    "        #map, our flattened image would be of dimension 16*16*24.\n",
    "        #out_features is the correspond number of classes we desire.\n",
    "        \n",
    "        \n",
    "    #Define models in PyTorch, define layers in the constructor and pass in all inputs in the forward function.\n",
    "    def forward(self, input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.relu1(output)\n",
    "        \n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "        \n",
    "        output = self.pool(output)\n",
    "        \n",
    "        output = self.conv3(output)\n",
    "        output = self.relu3(output)\n",
    "        \n",
    "        output = self.conv4(output)\n",
    "        output = self.relu4(output)\n",
    "        #fltten the output of network into dimension 16*16*24 \n",
    "        output = output.view(-1, 16*16*24)\n",
    "        \n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
